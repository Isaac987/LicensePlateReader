{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import easyocr\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.abspath(\"..\")\n",
    "\n",
    "PATHS = {\n",
    "    \"data\": os.path.join(ROOT, \"data\"),\n",
    "    \"models\": os.path.join(ROOT, \"models\"),\n",
    "}\n",
    "DATA = {\n",
    "    \"img00\" : os.path.join(PATHS[\"data\"], \"car00.webp\"),\n",
    "    \"img01\" : os.path.join(PATHS[\"data\"], \"car01.webp\"),\n",
    "    \"img02\" : os.path.join(PATHS[\"data\"], \"car02.jpg\"),\n",
    "    \"img03\" : os.path.join(PATHS[\"data\"], \"car03.jpg\"),\n",
    "    \"img04\" : os.path.join(PATHS[\"data\"], \"car04.jpg\"),\n",
    "    \"video\" : os.path.join(PATHS[\"data\"], \"video.mp4\"),\n",
    "}\n",
    "\n",
    "MODELS = {\n",
    "    \"plates_pt\" : os.path.join(PATHS[\"models\"], \"plates.pt\"),\n",
    "    \"plates_n_pt\" : os.path.join(PATHS[\"models\"], \"plates_n.pt\"),\n",
    "    \"plates_onnx\" : os.path.join(PATHS[\"models\"], \"plates.onnx\"),\n",
    "    \"platesv8_pt\" : os.path.join(PATHS[\"models\"], \"plates_yolov8.pt\"),\n",
    "    \"platesv8_onnx\" : os.path.join(PATHS[\"models\"], \"plates_yolov8.onnx\"),\n",
    "    \"platesv5n_onnx\" : os.path.join(PATHS[\"models\"], \"plates_yolov5n.onnx\"),\n",
    "}\n",
    "\n",
    "SELECTED_MODEL = MODELS[\"plates_n_pt\"]\n",
    "SELECTED_IMAGE = DATA[\"img01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX(MODELS[\"platesv5n_onnx\"])\n",
    "type(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net.getLayerNames()\n",
    "input_layer_idx = net.getLayerId(ln[0])\n",
    "net.getLayer(input_layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(cv2.imread(SELECTED_IMAGE), cv2.COLOR_BGR2RGB)\n",
    "height, width = image.shape[:2]\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image, 1/255, (640, 640), swapRB=False, crop=False)\n",
    "net.setInput(blob)\n",
    "outputs = net.forward()\n",
    "outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.transpose((0, 2, 1))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = outputs[0][:, 4] > 0.5\n",
    "idx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in outputs[0][idx]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = outputs[0][idx]\n",
    "rect = image.copy()\n",
    "\n",
    "for detection in detections:\n",
    "    conf = outputs[0][idx][-2]\n",
    "    x, y, w, h = detection[:4].astype(int)\n",
    "    x1, y1 = x-w//2, y-h//2\n",
    "    x2, y2 = x+w//2, y+h//2\n",
    "    x1 = x1 * width // 640\n",
    "    y1 = y1 * height // 640\n",
    "    x2 = x2 * width // 640\n",
    "    y2 = y2 * height // 640\n",
    "    top_left = (x1, y1)\n",
    "    bottom_right = (x2, y2)\n",
    "    rect = cv2.rectangle(rect, top_left, bottom_right, (255, 0, 0), 5)\n",
    "\n",
    "plt.imshow(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbboxv5(frame, width, height):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (640, 640), swapRB=False, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward()\n",
    "    idx = outputs[0][:, 4] > 0.80\n",
    "    rect = frame.copy()\n",
    "    detections = outputs[0][idx]\n",
    "    \n",
    "    for detection in detections:\n",
    "        conf = detection[-2]\n",
    "        x, y, w, h = detection[:4].astype(int)\n",
    "        x1, y1 = x-w//2, y-h//2\n",
    "        x2, y2 = x+w//2, y+h//2\n",
    "        x1 = x1 * width // 640\n",
    "        y1 = y1 * height // 640\n",
    "        x2 = x2 * width // 640\n",
    "        y2 = y2 * height // 640\n",
    "        top_left = (x1, y1)\n",
    "        bottom_right = (x2, y2)\n",
    "        rect = cv2.rectangle(rect, top_left, bottom_right, (255, 0, 0), 5)\n",
    "    \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbboxv8(frame, width, height):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (640, 640), swapRB=False, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward()\n",
    "    outputs = outputs.transpose((0, 2, 1))\n",
    "    idx = outputs[0][:, 4] > 0.50\n",
    "    rect = frame.copy()\n",
    "    detections = outputs[0][idx]\n",
    "    \n",
    "    for detection in detections:\n",
    "        conf = detection[-2]\n",
    "        x, y, w, h = detection[:4].astype(int)\n",
    "        x1, y1 = x-w//2, y-h//2\n",
    "        x2, y2 = x+w//2, y+h//2\n",
    "        x1 = x1 * width // 640\n",
    "        y1 = y1 * height // 640\n",
    "        x2 = x2 * width // 640\n",
    "        y2 = y2 * height // 640\n",
    "        top_left = (x1, y1)\n",
    "        bottom_right = (x2, y2)\n",
    "        rect = cv2.rectangle(rect, top_left, bottom_right, (255, 0, 0), 5)\n",
    "    \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(DATA[\"video\"])\n",
    "assert cap.isOpened()\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    new_frame_time = time.time()\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = int(fps)\n",
    "    fps = str(fps)\n",
    "    cv2.putText(frame, f\"{fps} fps\", (7, 70), cv2.FONT_HERSHEY_SIMPLEX, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "\n",
    "    rect = getbboxv5(frame, width, height)\n",
    "    # rect = getbboxv8(frame, width, height)\n",
    "\n",
    "    cv2.imshow(\"Plate Detection\", rect)\n",
    "\n",
    "    if (cv2.waitKey(5) & 0xFF == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PlateDetector import PlateDetector\n",
    "from Plate import Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m fps \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(fps)\n\u001b[0;32m     20\u001b[0m cv2\u001b[39m.\u001b[39mputText(frame, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfps\u001b[39m}\u001b[39;00m\u001b[39m fps\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m7\u001b[39m, \u001b[39m70\u001b[39m), cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m3\u001b[39m, (\u001b[39m100\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m3\u001b[39m, cv2\u001b[39m.\u001b[39mLINE_AA)\n\u001b[1;32m---> 22\u001b[0m plates \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mPredict(frame)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(plates)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m (cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m5\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39m27\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\iperkins\\Develop\\LicensePlateReader\\src\\PlateDetector.py:34\u001b[0m, in \u001b[0;36mPlateDetector.Predict\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     31\u001b[0m plates \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(conf_predictions\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m i, prediction \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(conf_predictions):\n\u001b[1;32m---> 34\u001b[0m     confidence: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m prediction[:\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m]\n\u001b[0;32m     35\u001b[0m     x, y, w, h \u001b[39m=\u001b[39m prediction[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[0;32m     37\u001b[0m     factor_w: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m w \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "pd = PlateDetector(MODELS[\"platesv5n_onnx\"], 640)\n",
    "\n",
    "cap = cv2.VideoCapture(DATA[\"video\"])\n",
    "assert cap.isOpened()\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    new_frame_time = time.time()\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = int(fps)\n",
    "    fps = str(fps)\n",
    "    cv2.putText(frame, f\"{fps} fps\", (7, 70), cv2.FONT_HERSHEY_SIMPLEX, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    plates = pd.Predict(frame)\n",
    "    print(plates)\n",
    "\n",
    "    if (cv2.waitKey(5) & 0xFF == 27):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
